{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrating Model Build and Registration with SageMaker Pipelines\n",
    "\n",
    "> *This notebook is designed to work with the `Python 3 (Data Science)` kernel on SageMaker Studio.*\n",
    "\n",
    "Amazon SageMaker offers Machine Learning application developers and Machine Learning operations engineers the ability to orchestrate SageMaker jobs and author reproducible Machine Learning pipelines, deploy custom-build models for inference in real-time with low latency or offline inferences with Batch Transform, and track lineage of artifacts. You can institute sound operational practices in deploying and monitoring production workflows, deployment of model artifacts, and track artifact lineage through a simple interface, adhering to safety and best-practice paradigmsfor Machine Learning application development.\n",
    "\n",
    "The [SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) service supports a SageMaker Machine Learning Pipeline Domain Specific Language (DSL), which is a declarative Json specification. This DSL defines a Directed Acyclic Graph (DAG) of pipeline parameters and SageMaker job steps. The [SageMaker Python Software Developer Kit (SDK)](https://sagemaker.readthedocs.io/en/stable/) streamlines the generation of the pipeline DSL using constructs that are already familiar to engineers and scientists alike.\n",
    "\n",
    "The [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html) is where trained models are stored, versioned, and managed. Data Scientists and Machine Learning Engineers can compare model versions, approve models for deployment, and deploy models from different AWS accounts, all from a single Model Registry. SageMaker enables customers to follow the best practices with ML Ops and getting started right. Customers are able to standup a full ML Ops end-to-end system with a single API call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Pipelines\n",
    "\n",
    "A SageMaker Pipeline defines a Directed Acyclic Graph (DAG) of steps and conditions to orchestrate SageMaker jobs and resource creation - supporting a [broad range of activities](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html) including:\n",
    "\n",
    "* **Processing Job steps** - A simplified, managed experience on SageMaker to run data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation.\n",
    "* **Training Job steps** - An iterative process that teaches a model to make predictions by presenting examples from a training dataset.\n",
    "* **Registering Models** - Creates a model package resource in the Model Registry that can be used to create deployable models in Amazon SageMaker.\n",
    "* **Creating Model steps** - Create a model for use in transform steps or later publication as an endpoint.\n",
    "* **Transform Job steps** - A batch transform to preprocess datasets to remove noise or bias that interferes with training or inference from your dataset, get inferences from large datasets, and run inference when you don't need a persistent endpoint.\n",
    "* **Conditional step execution** - Provides conditional execution of branches in a pipeline.\n",
    "* **Parameterized Pipeline executions** - Allows pipeline executions to vary by supplied parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline that we'll create in this example follows a typical Machine Learning Application pattern of pre-processing, training, evaluation, and conditional model registration and publication, if the quality of the model is sufficient.\n",
    "\n",
    "![](imgs/sm-pipelines.png \"A typical ML Application pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the various Python libraries we'll use in the exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # The general-purpose AWS SDK for Python\n",
    "import sagemaker  # High-level Python SDK for Amazon SageMaker\n",
    "\n",
    "print(f\"sagemaker SDK v{sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can connect to AWS services and **configure**:\n",
    "\n",
    "- The [Amazon S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html) and prefix to use for storing data and artifacts.\n",
    "- The [IAM role](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) ARN to be used for accessing data and other resources.\n",
    "- Some additional **names and prefixes** for the pipeline and model package resources the notebook will create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.Session()\n",
    "s3 = boto3.resource(\"s3\")  # Amazon S3\n",
    "\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pipelines-churn\"\n",
    "print(f\"Saving S3 data to: s3://{bucket}/{prefix}\")\n",
    "\n",
    "base_job_prefix=\"CustomerChurn\"\n",
    "model_package_group_name = \"ChurnModelPackageGroup-v1\"\n",
    "pipeline_name = \"ChurnPipeline-v1\"\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f\"Using IAM role: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gather the data\n",
    "\n",
    "This example will use a synthetic customer churn dataset from the public `sagemaker-sample-files` bucket: The same as the previous Autopilot notebook. In a real scenario you would access your own data, typically on your own S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data from s3 to our local folder\n",
    "!aws s3 cp s3://sagemaker-sample-files/datasets/tabular/synthetic/churn.txt ./data/churn.txt\n",
    "\n",
    "# Copy the file to our own S3 bucket with a csv extension\n",
    "raw_data_key = f\"{prefix}/data/RawData.csv\"\n",
    "s3.Bucket(bucket).Object(raw_data_key).upload_file(\"./data/churn.txt\")\n",
    "raw_data_s3uri = f\"s3://{bucket}/{raw_data_key}\"\n",
    "\n",
    "print(f\"\\nRaw data loaded to:\\n{raw_data_s3uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Processing step for feature engineering\n",
    "\n",
    "For our use case we keep the actual pre-processing code within a separate python file [preprocess.py](preprocess.py). This script will drop irrelevant columns, encode categorical values, create a target value and split the data between test, train and validation.\n",
    "\n",
    "> ⚠️ **Note:** Below we use these *Pipeline parameter objects* in place of actual values - for example:\n",
    ">\n",
    "> 1. `processing_instance_type`\n",
    "> 1. `processing_instance_count`, and\n",
    "> 1. `input_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import CacheConfig, ProcessingStep\n",
    "\n",
    "# 1. parameters for the pre-processing stage\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "processing_instance_count = ParameterInteger( name=\"ProcessingInstanceCount\", default_value=1,)\n",
    "processing_instance_type = ParameterString( name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\",)\n",
    "input_data = ParameterString( name=\"InputDataUrl\", default_value=raw_data_s3uri, )\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=processing_instance_type,  # (Pipeline parameter)\n",
    "    instance_count=processing_instance_count,  # (Pipeline parameter)\n",
    "    # base_job_name=f\"{base_job_prefix}/sklearn-CustomerChurn-preprocess\",\n",
    "    sagemaker_session=sm_session,\n",
    "    role=role,\n",
    ")\n",
    "step_process = ProcessingStep(\n",
    "    name=\"CustomerChurnProcess\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name=\"raw\",\n",
    "            source=input_data,  # (Pipeline parameter)\n",
    "            destination=\"/opt/ml/processing/input/raw\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"./preprocess.py\",\n",
    "    cache_config=CacheConfig(enable_caching=True, expire_after=\"T2H\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training step for generating model artifacts\n",
    "\n",
    "On this step we will define [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) as our algorithm of choice. This example uses **both**:\n",
    "\n",
    "- **Pipeline input parameters** which can be customized at execution time (`training_instance_type`, `training_max_depth`), and\n",
    "- **Dependencies** from the previous processing step (`step_process.properties.{***}`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# 2. parameters for the training stage. No need to import ParameterString since it was imported earlier.\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\",)\n",
    "training_max_depth = ParameterString(name=\"TrainingMaxDepth\", default_value=\"5\",)        \n",
    "\n",
    "model_path = f\"s3://{bucket}/{base_job_prefix}/CustomerChurnTrain\"\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",  # we are using the Sagemaker built in xgboost algorithm\n",
    "    region=sm_session.boto_session.region_name,  # e.g. 'us-east-1'\n",
    "    version=\"1.3-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,  # (Pipeline parameter)\n",
    ")\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,  # (Pipeline parameter)\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"{base_job_prefix}/CustomerChurn-train\",\n",
    "    sagemaker_session=sm_session,\n",
    "    role=role,\n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=50,\n",
    "    max_depth=training_max_depth,  # (Pipeline parameter)\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")\n",
    "step_train = TrainingStep(\n",
    "    name=\"CustomerChurnTrain\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            # Use an output from one step as an input (dependency) in another:\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            # Use an output from one step as an input (dependency) in another:\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Processing step for evaluation\n",
    "\n",
    "This step uses one parameter which we can customize at execution time (`processing_instance_type`), and again references outputs from other steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "# processing_instance_type parameter was already defined in stage 2 but it is reused here\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,  # (Pipeline parameter)\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{base_job_prefix}/script-CustomerChurn-eval\",\n",
    "    sagemaker_session=sm_session,\n",
    "    role=role,\n",
    ")\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"CustomerChurnEval\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[ ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"), ],\n",
    "    code=\"./evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Register model step that will be conditionally executed\n",
    "\n",
    "Pipelines allow us to have conditional steps, to register models into our registry and optionally to publish these to staging. A common usage is to check a minimum threshold (using F1 in our case) and only publish into our registry if it is higher than a given threshold (0.8 in our case). \n",
    "\n",
    "This step uses one parameter which we can customize at execution time: \n",
    "`model_approval_status`\n",
    "\n",
    "> ▶️ **Question:** *Which other variables could we add from this section as parameter for the pipeline?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "# Parameter for the model register stage\n",
    "# (ModelApprovalStatus can be set to a default of \"Approved\" if you don't want manual approval)\n",
    "model_approval_status = ParameterString( name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\",)\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Register model step that will be conditionally executed\n",
    "step_register = RegisterModel(\n",
    "    name=\"CustomerChurnRegisterModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "# Condition step for evaluating model quality and branching execution\n",
    "cond_register = ConditionGreaterThanOrEqualTo(  # You can change the condition here\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        # This should follow the structure of your report_dict defined in the evaluate.py file:\n",
    "        json_path=\"binary_classification_metrics.f1.value\",\n",
    "    ),\n",
    "    right=0.8,  # TODO: add as a pipeline parameter\n",
    ")    \n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CustomerChurnAccuracyCond\",\n",
    "    conditions=[cond_register],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Construct Pipeline \n",
    "\n",
    "With the steps and pipeline-level parameters all defined, we're ready to create the overall [Pipeline](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#pipeline) and register it with SageMaker.\n",
    "\n",
    "> ⚠️ **Remember:** if you added any additional parameters, you will need to add them to this pipeline definition as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_max_depth,            \n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=sm_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline definition is not actually submitted to the SageMaker service until we `upsert()` it. The role passed in here with the definition will be used by the workflow service to create all the jobs defined in the steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After `upsert()`ing your pipeline, it should be registered with the SageMaker APIs and ready to use. For example, you should see the pipeline available in the SageMaker Studio UI through the *Resources > Pipelines* sidebar menu:\n",
    "\n",
    "![](imgs/sm-pipeline-registered.png \"Screenshot of SageMaker Studio UI showing registered churn pipeline\")\n",
    "\n",
    "### 7. Run the Pipeline\n",
    "\n",
    "Before we start experimenting with the execution parameters and UI though, let's see how to start and check the pipeline with default parameters from code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Pipeline Operations: examining and waiting for pipeline execution\n",
    "\n",
    "Starting a pipeline creates an **execution** instance, which can be queried to list the steps in the execution and find out more about its progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the execution by invoking `wait()` on the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Parameterized Executions\n",
    "\n",
    "We can run additional executions of the pipeline specifying different pipeline parameters. The parameters argument is a dictionary whose names are the parameter names, and whose values are the primitive values to use as overrides of the defaults.\n",
    "\n",
    "Of particular note, based on the performance of the model, we may want to kick off another pipeline execution, but this time on a compute-optimized instance type and set the model approval status automatically be \"Approved\". This means that the model package version generated by the `RegisterModel` step will automatically be ready for deployment through CI/CD pipelines, such as with SageMaker Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=\"ml.c5.xlarge\",\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "        TrainingMaxDepth=\"6\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "▶️ **Run** the previous execution from the **UI in Sagemaker Studio** instead of using a Notebook.\n",
    "\n",
    "▶️ **Add** the minimum F1 score for model registration as a **parameter** to the pipeline, instead of the hard-coded `0.8` value used above. Check you can update and run your pipeline successfully to override the threshold!"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
